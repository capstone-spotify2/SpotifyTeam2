{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is functions to running hashing vectorizer on raw lyrics input and outputs a dimensionality reduced feature vectors for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2009, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Aritist</th>\n",
       "      <th>tag</th>\n",
       "      <th>Song_txt_loc</th>\n",
       "      <th>Song_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TRAAAED128E0783FAB</td>\n",
       "      <td>It's About Time</td>\n",
       "      <td>Jamie Cullum</td>\n",
       "      <td>relax</td>\n",
       "      <td>./lyrics_new/jamiecullum_itsabouttime.txt</td>\n",
       "      <td>Walking down to the water's edgeWhere I have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>TRAACER128F4290F96</td>\n",
       "      <td>Setting Fire to Sleeping Giants</td>\n",
       "      <td>The Dillinger Escape Plan</td>\n",
       "      <td>energetic</td>\n",
       "      <td>./lyrics_new/dillingerescapeplan_settingfireto...</td>\n",
       "      <td>First off Let me say you look so tired... Res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>TRAADVO128E07999E9</td>\n",
       "      <td>Oh God</td>\n",
       "      <td>Jamie Cullum</td>\n",
       "      <td>relax</td>\n",
       "      <td>./lyrics_new/jamiecullum_ohgod.txt</td>\n",
       "      <td>I know it's been a while since I have talked ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>TRAAFGQ128F427D884</td>\n",
       "      <td>One Last Time</td>\n",
       "      <td>The Kooks</td>\n",
       "      <td>sad</td>\n",
       "      <td>./lyrics_new/kooks_onelasttime.txt</td>\n",
       "      <td>Can I hold you one last time To fight the fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>TRAAGCZ128F93210FD</td>\n",
       "      <td>Let's Get It Started</td>\n",
       "      <td>Black Eyed Peas</td>\n",
       "      <td>happy</td>\n",
       "      <td>./lyrics_new/blackeyedpeas_letsgetitstarted.txt</td>\n",
       "      <td>Let's get it started in here...  And the bass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                  id                             Name  \\\n",
       "0           0      0  TRAAAED128E0783FAB                  It's About Time   \n",
       "1           1      3  TRAACER128F4290F96  Setting Fire to Sleeping Giants   \n",
       "2           2      7  TRAADVO128E07999E9                           Oh God   \n",
       "3           3      8  TRAAFGQ128F427D884                    One Last Time   \n",
       "4           4     10  TRAAGCZ128F93210FD             Let's Get It Started   \n",
       "\n",
       "                     Aritist        tag  \\\n",
       "0               Jamie Cullum      relax   \n",
       "1  The Dillinger Escape Plan  energetic   \n",
       "2               Jamie Cullum      relax   \n",
       "3                  The Kooks        sad   \n",
       "4            Black Eyed Peas      happy   \n",
       "\n",
       "                                        Song_txt_loc  \\\n",
       "0          ./lyrics_new/jamiecullum_itsabouttime.txt   \n",
       "1  ./lyrics_new/dillingerescapeplan_settingfireto...   \n",
       "2                 ./lyrics_new/jamiecullum_ohgod.txt   \n",
       "3                 ./lyrics_new/kooks_onelasttime.txt   \n",
       "4    ./lyrics_new/blackeyedpeas_letsgetitstarted.txt   \n",
       "\n",
       "                                         Song_lyrics  \n",
       "0   Walking down to the water's edgeWhere I have ...  \n",
       "1   First off Let me say you look so tired... Res...  \n",
       "2   I know it's been a while since I have talked ...  \n",
       "3   Can I hold you one last time To fight the fee...  \n",
       "4   Let's get it started in here...  And the bass...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Song_with_lyrics.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'blue'>\n",
    "Note: The work of matching the lyrics with songs takes long time because the raw lyrics and song information came from different sources. Some songs might not be able to match with the lyrics due to the way that artist name has been written in difference sources. Additionally, scraping lyrics takes extremely long time, not all the songs have been scrped down. Therefore, so far we only used around 2000 data points to test if hashing vectorizer is a good way to increase accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyr = df.Song_lyrics.values\n",
    "lyr2 = ['' if type(i) != str else i for i in lyr ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lyr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv = HashingVectorizer(n_features=50)\n",
    "trans = hv.transform(lyr2)\n",
    "# convert to dense matrix\n",
    "dense = trans.todense()\n",
    "dense = dense.tolist()\n",
    "final_tag = df['tag'].values\n",
    "len(final_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"blue\">\n",
    "convert to a dataframe with response variable to a numerical value with all the features with hashing vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(dense)):\n",
    "    dense[i].append(final_tag[i])\n",
    "final_df= pd.DataFrame.from_records(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.202241</td>\n",
       "      <td>-0.057783</td>\n",
       "      <td>0.173350</td>\n",
       "      <td>-0.028892</td>\n",
       "      <td>-0.057783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.202241</td>\n",
       "      <td>0.173350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086675</td>\n",
       "      <td>-0.057783</td>\n",
       "      <td>-0.028892</td>\n",
       "      <td>-0.144458</td>\n",
       "      <td>-0.751182</td>\n",
       "      <td>0.144458</td>\n",
       "      <td>-0.028892</td>\n",
       "      <td>0.057783</td>\n",
       "      <td>0.086675</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184988</td>\n",
       "      <td>0.061663</td>\n",
       "      <td>0.061663</td>\n",
       "      <td>0.030831</td>\n",
       "      <td>-0.184988</td>\n",
       "      <td>0.030831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.339145</td>\n",
       "      <td>-0.061663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.030831</td>\n",
       "      <td>-0.030831</td>\n",
       "      <td>-0.154157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.154157</td>\n",
       "      <td>0.030831</td>\n",
       "      <td>0.030831</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274352</td>\n",
       "      <td>0.078386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078386</td>\n",
       "      <td>-0.039193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.235159</td>\n",
       "      <td>0.117579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548703</td>\n",
       "      <td>-0.235159</td>\n",
       "      <td>-0.078386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235159</td>\n",
       "      <td>-0.195965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135457</td>\n",
       "      <td>0.067729</td>\n",
       "      <td>-0.135457</td>\n",
       "      <td>0.067729</td>\n",
       "      <td>-0.203186</td>\n",
       "      <td>-0.067729</td>\n",
       "      <td>0.067729</td>\n",
       "      <td>-0.067729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406371</td>\n",
       "      <td>-0.067729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.203186</td>\n",
       "      <td>-0.406371</td>\n",
       "      <td>0.067729</td>\n",
       "      <td>-0.135457</td>\n",
       "      <td>-0.135457</td>\n",
       "      <td>-0.067729</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.317518</td>\n",
       "      <td>0.021168</td>\n",
       "      <td>-0.370438</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.021168</td>\n",
       "      <td>-0.095255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.031752</td>\n",
       "      <td>-0.095255</td>\n",
       "      <td>-0.010584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063504</td>\n",
       "      <td>-0.010584</td>\n",
       "      <td>0.031752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.285766</td>\n",
       "      <td>0.063504</td>\n",
       "      <td>-0.021168</td>\n",
       "      <td>0.624452</td>\n",
       "      <td>0.074088</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.000000 -0.202241 -0.057783  0.173350 -0.028892 -0.057783  0.000000   \n",
       "1  0.000000  0.184988  0.061663  0.061663  0.030831 -0.184988  0.030831   \n",
       "2  0.000000  0.274352  0.078386  0.000000  0.078386 -0.039193  0.000000   \n",
       "3  0.000000  0.135457  0.067729 -0.135457  0.067729 -0.203186 -0.067729   \n",
       "4 -0.317518  0.021168 -0.370438  0.010584  0.021168 -0.095255  0.000000   \n",
       "\n",
       "         7         8         9  ...         41        42        43        44  \\\n",
       "0  0.000000 -0.202241  0.173350 ...   0.086675 -0.057783 -0.028892 -0.144458   \n",
       "1  0.000000 -0.339145 -0.061663 ...   0.308313  0.000000 -0.030831 -0.030831   \n",
       "2  0.000000 -0.235159  0.117579 ...   0.548703 -0.235159 -0.078386  0.000000   \n",
       "3  0.067729 -0.067729  0.000000 ...   0.406371 -0.067729  0.000000 -0.203186   \n",
       "4 -0.031752 -0.095255 -0.010584 ...   0.063504 -0.010584  0.031752  0.000000   \n",
       "\n",
       "         45        46        47        48        49   50  \n",
       "0 -0.751182  0.144458 -0.028892  0.057783  0.086675  4.0  \n",
       "1 -0.154157  0.000000 -0.154157  0.030831  0.030831  3.0  \n",
       "2  0.235159 -0.195965  0.000000  0.000000  0.000000  4.0  \n",
       "3 -0.406371  0.067729 -0.135457 -0.135457 -0.067729  2.0  \n",
       "4 -0.285766  0.063504 -0.021168  0.624452  0.074088  1.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[50] = final_df[50].map({'happy': 1.0, 'sad': 2.0,'energetic': 3.0, 'relax': 4.0})\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"blue\">\n",
    "### split the data points to train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>0.021243</td>\n",
       "      <td>0.127458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042486</td>\n",
       "      <td>-0.021243</td>\n",
       "      <td>0.021243</td>\n",
       "      <td>-0.063729</td>\n",
       "      <td>-0.021243</td>\n",
       "      <td>-0.106215</td>\n",
       "      <td>0.106215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276159</td>\n",
       "      <td>-0.106215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.084972</td>\n",
       "      <td>0.424859</td>\n",
       "      <td>-0.063729</td>\n",
       "      <td>0.084972</td>\n",
       "      <td>0.042486</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.159719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063888</td>\n",
       "      <td>-0.031944</td>\n",
       "      <td>-0.031944</td>\n",
       "      <td>-0.063888</td>\n",
       "      <td>-0.031944</td>\n",
       "      <td>-0.031944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383326</td>\n",
       "      <td>0.351382</td>\n",
       "      <td>-0.127775</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>-0.319438</td>\n",
       "      <td>-0.031944</td>\n",
       "      <td>-0.159719</td>\n",
       "      <td>0.063888</td>\n",
       "      <td>0.255551</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057831</td>\n",
       "      <td>-0.057831</td>\n",
       "      <td>0.057831</td>\n",
       "      <td>-0.057831</td>\n",
       "      <td>-0.115663</td>\n",
       "      <td>-0.057831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.404820</td>\n",
       "      <td>-0.057831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231326</td>\n",
       "      <td>0.057831</td>\n",
       "      <td>-0.057831</td>\n",
       "      <td>-0.057831</td>\n",
       "      <td>-0.289157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.057831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0.041065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.082130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.041065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.164260</td>\n",
       "      <td>0.123195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.041065</td>\n",
       "      <td>0.041065</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137073</td>\n",
       "      <td>-0.091382</td>\n",
       "      <td>0.045691</td>\n",
       "      <td>-0.045691</td>\n",
       "      <td>-0.045691</td>\n",
       "      <td>-0.045691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.319838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137073</td>\n",
       "      <td>0.045691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.091382</td>\n",
       "      <td>0.091382</td>\n",
       "      <td>0.091382</td>\n",
       "      <td>0.045691</td>\n",
       "      <td>-0.045691</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "1088  0.021243  0.127458  0.000000  0.042486 -0.021243  0.021243 -0.063729   \n",
       "769   0.000000 -0.159719  0.000000  0.000000  0.063888 -0.031944 -0.031944   \n",
       "1305  0.000000  0.057831 -0.057831  0.057831 -0.057831 -0.115663 -0.057831   \n",
       "436   0.041065  0.000000 -0.082130  0.000000  0.082130  0.000000  0.000000   \n",
       "924   0.000000  0.137073 -0.091382  0.045691 -0.045691 -0.045691 -0.045691   \n",
       "\n",
       "            7         8         9  ...         41        42        43  \\\n",
       "1088 -0.021243 -0.106215  0.106215 ...   0.276159 -0.106215  0.000000   \n",
       "769  -0.063888 -0.031944 -0.031944 ...   0.383326  0.351382 -0.127775   \n",
       "1305  0.000000 -0.404820 -0.057831 ...   0.231326  0.057831 -0.057831   \n",
       "436   0.000000 -0.041065  0.000000 ...   0.287456  0.000000  0.000000   \n",
       "924   0.000000 -0.319838  0.000000 ...   0.137073  0.045691  0.000000   \n",
       "\n",
       "            44        45        46        47        48        49   50  \n",
       "1088  0.000000 -0.084972  0.424859 -0.063729  0.084972  0.042486  1.0  \n",
       "769   0.031944 -0.319438 -0.031944 -0.159719  0.063888  0.255551  2.0  \n",
       "1305 -0.057831 -0.289157  0.000000  0.000000 -0.057831  0.000000  1.0  \n",
       "436   0.000000 -0.164260  0.123195  0.000000 -0.041065  0.041065  2.0  \n",
       "924   0.000000 -0.091382  0.091382  0.091382  0.045691 -0.045691  1.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk = np.random.randint(len(final_df),size = len(final_df))\n",
    "train_index = msk[:int(0.75*len(final_df))]\n",
    "test_index = msk[int(0.75*len(final_df)):]\n",
    "train = final_df.iloc[train_index]\n",
    "test = final_df.iloc[test_index]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train.values[:,:-1]\n",
    "train_y = train.values[:,-1]\n",
    "test_x = test.values[:,:-1]\n",
    "test_y = test.values[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"blue\">\n",
    "### apply basic classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of SVM with HashingVectorizer is: 0.419483101392\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_x, train_y)  \n",
    "y_hat = clf.predict(test_x)\n",
    "score = clf.score(test_x,test_y)\n",
    "print \"The accuracy of SVM with HashingVectorizer is: \"+ str(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest with HashingVectorizer is: 0.479125248509\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_short = RandomForestClassifier(n_estimators = 15, max_depth =5)\n",
    "RF_short.fit(train_x, train_y)\n",
    "y_pred_rf_short = RF_short.predict(test_x)\n",
    "y_pred_rf_short_prob = RF_short.predict_proba(test_x)\n",
    "y_score_rf_short = RF_short.score(test_x,test_y)\n",
    "print \"The accuracy of Random Forest with HashingVectorizer is: \"+ str(y_score_rf_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Gaussian NB with HashingVectorizer is: 0.403578528827\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf1 = GaussianNB()\n",
    "clf1.fit(train_x, train_y)\n",
    "nb_score = clf1.score(test_x,test_y)\n",
    "print \"The accuracy of Gaussian NB with HashingVectorizer is: \"+ str(nb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color = \"blue\">\n",
    "# literature Review on Hashing Vectorizer\n",
    "Among all the dimensionality reduction methods we have tried, Hashing vectorizer gives the best result. Hashingvectorizer uses the hashing trick to find the token string name to feature integer index mapping and convert a collection of text documents to a matrix of token occurrences.\n",
    "\n",
    "We started exploring this method because we want to reduce the 5000 features in bag-of-words to a low dimension. Originally, we want to use hashingvectorizer the same way as tf-idf, and PCA, where we input bag-of-words as the input. However, hashing vectorizer requires raw lyrics as inputs because hashing vectorizer will tokenize the words into different bins according to the chronological order of the words in the sentence. Using the hashing trick builded in the function, the hashing vectorizer outputs nxm feature matrix where n is number of observation, m is the number of features we want to reduce to.\n",
    "\n",
    "Using Hashingvectorizer, we are able to increase the accuracy of the prediction and gets the highest accuracy in the basic classification model compare to other dimensionality reduction methods.\n",
    "# analysis:\n",
    "from the result above, we can see that even with this small amount of data set, we are able to get the best accuracy compare to other dimensionality reduction. Among all three basic classification model, Random Forest gives us the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select n_features for best result\n",
    "we do it by having a train, validation, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 (2009, 2) 11 (2009, 12) 21 (2009, 22) 31 (2009, 32) 41 (2009, 42) 51 (2009, 52) 61 (2009, 62) 71 (2009, 72) 81 (2009, 82) 91 (2009, 92) 101 (2009, 102) 111 (2009, 112) 121 (2009, 122) 131 (2009, 132) 141 (2009, 142) 151 (2009, 152) 161 (2009, 162) 171 (2009, 172) 181 (2009, 182) 191 (2009, 192)\n"
     ]
    }
   ],
   "source": [
    "final_tag = df['tag'].values\n",
    "msk = np.random.randint(len(final_df),size = len(final_df))\n",
    "train_index = msk[:int(0.60*len(final_df))]\n",
    "valid_index = msk[int(0.60*len(final_df)):int(0.80*len(final_df))]\n",
    "test_index = msk[int(0.80*len(final_df)):]\n",
    "y_score_rf_l = []\n",
    "\n",
    "for index in range(1,201,10):\n",
    "    print index,\n",
    "    hv = HashingVectorizer(n_features=index)\n",
    "    trans = hv.transform(lyr2)\n",
    "    # convert to dense matrix\n",
    "    dense = trans.todense()\n",
    "    dense = dense.tolist()\n",
    "    for i in range(len(dense)):\n",
    "        dense[i].append(final_tag[i])\n",
    "    final_df= pd.DataFrame.from_records(dense)\n",
    "    print(final_df.shape),\n",
    "    final_df[index] = final_df[index].map({'happy': 1.0, 'sad': 2.0,'energetic': 3.0, 'relax': 4.0})\n",
    "    # split train_test file\n",
    "    train = final_df.iloc[train_index]\n",
    "    valid = final_df.iloc[valid_index]\n",
    "    test = final_df.iloc[test_index]\n",
    "    train_x = train.values[:,:-1]\n",
    "    train_y = train.values[:,-1]\n",
    "    valid_x = valid.values[:,:-1]\n",
    "    valid_y = valid.values[:,-1]\n",
    "    test_x = test.values[:,:-1]\n",
    "    test_y = test.values[:,-1]\n",
    "    RF_short = RandomForestClassifier(n_estimators = 15, max_depth =5)\n",
    "    RF_short.fit(train_x, train_y)\n",
    "    y_pred_rf_short = RF_short.predict(test_x)\n",
    "    y_pred_rf_short_prob = RF_short.predict_proba(test_x)\n",
    "    y_score_rf_l.append(RF_short.score(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_score_rf_l.index(max(y_score_rf_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2009, 62)\n"
     ]
    }
   ],
   "source": [
    "index = 61\n",
    "hv = HashingVectorizer(n_features=index)\n",
    "trans = hv.transform(lyr2)\n",
    "# convert to dense matrix\n",
    "dense = trans.todense()\n",
    "dense = dense.tolist()\n",
    "for i in range(len(dense)):\n",
    "    dense[i].append(final_tag[i])\n",
    "final_df= pd.DataFrame.from_records(dense)\n",
    "print(final_df.shape),\n",
    "final_df[index] = final_df[index].map({'happy': 1.0, 'sad': 2.0,'energetic': 3.0, 'relax': 4.0})\n",
    "# split train_test file\n",
    "train = final_df.iloc[train_index]\n",
    "valid = final_df.iloc[valid_index]\n",
    "test = final_df.iloc[test_index]\n",
    "train_x = train.values[:,:-1]\n",
    "train_y = train.values[:,-1]\n",
    "valid_x = valid.values[:,:-1]\n",
    "valid_y = valid.values[:,-1]\n",
    "test_x = test.values[:,:-1]\n",
    "test_y = test.values[:,-1]\n",
    "RF_short = RandomForestClassifier(n_estimators = 15, max_depth =5)\n",
    "RF_short.fit(train_x, train_y)\n",
    "y_pred_rf_short = RF_short.predict(test_x)\n",
    "y_pred_rf_short_prob = RF_short.predict_proba(test_x)\n",
    "y_score = RF_short.score(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Random Forest with HashingVectorizer after cross validation is: 0.5\n"
     ]
    }
   ],
   "source": [
    "print \"The accuracy of Random Forest with HashingVectorizer after cross validation is: \"+ str(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
